{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3450a53-9251-4268-8670-c78cbef84051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd39815-6639-4219-a04f-9d036c28a40e",
   "metadata": {},
   "source": [
    "##Customer Churn Prediction - Feature Engineering & Model Training\n",
    "#Step 1 :Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd788960-7e4a-4ab2-bdab-4c2042a00181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/user/Desktop/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85eac346-e7ee-4c96-b39a-362cb58f5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "912de1e4-dc6d-4497-826a-5082dd60233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a51c46-15d0-45d3-b932-cde4cdba4a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           object\n",
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54d7fe-7855-458e-9357-db19591ecf13",
   "metadata": {},
   "source": [
    "##  Step 3: Label Encoding for Categorical Features\n",
    "Convert text data (like Yes/No, Male/Female) into numbers using LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a66705-8880-49f7-9ec1-aa27e1b88f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "                                                           #Covert all text to numbers in defined column\n",
    "le = LabelEncoder()\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1d374-24ac-49d4-91d1-121cb80d5803",
   "metadata": {},
   "source": [
    " # STEP 4: Feature & Target Split\n",
    "Split the dataset into input features (X) and target variable (y).\n",
    "##  Step 5: Train-Test Split\n",
    "Split the data into 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e24566d-9a0d-41c7-b92b-ae39ab97ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba7e368-2d0b-4e8a-a9f5-9ee78ebfed31",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Train 3 different models to predict customer churn.\n",
    "\n",
    "## 1: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "909b5610-4c09-4b08-89b6-572823cf8d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(max_iter=2000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e968a1-185b-479d-a1b6-fa4b6831a048",
   "metadata": {},
   "source": [
    "##  Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9074cb7-faa6-4fec-9ba9-0f2b8fa067f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad77e1-2ca0-4a77-937d-dbd49c87bfa0",
   "metadata": {},
   "source": [
    "##  XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ab6f829-ad1e-4aff-8ea6-b2e5e19532bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:37:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3c1b72-47f6-40cb-aa80-223b3b521d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1036\n",
      "           1       0.68      0.56      0.61       373\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.77      0.73      0.75      1409\n",
      "weighted avg       0.81      0.81      0.81      1409\n",
      "\n",
      "[[938  98]\n",
      " [164 209]]\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1036\n",
      "           1       0.67      0.50      0.57       373\n",
      "\n",
      "    accuracy                           0.80      1409\n",
      "   macro avg       0.75      0.70      0.72      1409\n",
      "weighted avg       0.79      0.80      0.79      1409\n",
      "\n",
      "[[943  93]\n",
      " [188 185]]\n",
      "\n",
      "XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      1036\n",
      "           1       0.61      0.55      0.58       373\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.72      0.71      0.72      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n",
      "[[904 132]\n",
      " [169 204]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Logistic Regression:\\n\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "print()\n",
    "\n",
    "print(\"Random Forest:\\n\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print()\n",
    "\n",
    "print(\"XGBoost:\\n\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb3bff-232c-40c0-b0f9-21c3b7444f5b",
   "metadata": {},
   "source": [
    " Models trained successfully.  \n",
    "Next Step: Evaluate each model using classification metrics and select the best-performing one.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
